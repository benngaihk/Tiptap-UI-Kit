/**
 * AI API Service
 * Provides AI streaming capabilities using user configuration or environment variables
 */

import { getAiRequestConfig } from '@/ai/config/useAiConfig'

// AI Callback interface used by the extensions
export interface AiStreamCallback {
  onStart?: () => void
  onMessage?: (message: { content: string }) => void
  onStop?: () => void
  onError?: (error: Error) => void
}

export interface AiApiResponse {
  success: boolean
  content?: string
  error?: string
}

/**
 * Load API configuration
 * Priority: User config > Environment variables > Defaults
 */
function getAiConfig() {
  // First check user config (localStorage)
  const userConfig = getAiRequestConfig()
  if (userConfig) {
    return {
      provider: userConfig.provider,
      apiKey: userConfig.apiKey,
      baseUrl: userConfig.endpoint,
      model: userConfig.model,
      timeout: userConfig.timeout,
    }
  }

  // Fall back to environment variables
  const env = import.meta.env || {}
  return {
    provider: env.VITE_AI_PROVIDER || 'openai',
    apiKey: env.VITE_AI_API_KEY || '',
    baseUrl: env.VITE_AI_BASE_URL || '',
    model: env.VITE_AI_MODEL || 'gpt-4o-mini',
    timeout: DEFAULT_TIMEOUT,
  }
}

// Get base URL for provider
function getBaseUrl(provider: string, customUrl: string): string {
  if (customUrl) return customUrl
  const urls: Record<string, string> = {
    openai: 'https://api.openai.com/v1',
    aliyun: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    deepseek: 'https://api.deepseek.com/v1',
    ollama: 'http://localhost:11434/api',
  }
  return urls[provider] || urls.openai
}

// Default timeout for AI requests (60 seconds)
const DEFAULT_TIMEOUT = 60000

/**
 * Simulate AI streaming response for demo purposes
 * Shows how the AI feature works without requiring API key configuration
 */
async function simulateAiStream(
  callback: AiStreamCallback,
  demoType: 'continue' | 'polish' | 'summarize' | 'translate' | 'custom'
): Promise<void> {
  const demoMessages: Record<typeof demoType, string> = {
    continue: 'è¿™æ˜¯ AI ç»­å†™åŠŸèƒ½çš„æ¼”ç¤ºæ•ˆæœã€‚\n\nğŸ’¡ æç¤ºï¼šè¦ä½¿ç”¨çœŸå®çš„ AI åŠŸèƒ½ï¼Œè¯·åœ¨å·¥å…·æ çš„ AI è®¾ç½®ä¸­é…ç½®æ‚¨çš„ API Keyã€‚\n\næ”¯æŒçš„ AI æä¾›å•†ï¼š\nâ€¢ OpenAI (GPT-4, GPT-3.5)\nâ€¢ é˜¿é‡Œäº‘é€šä¹‰åƒé—®\nâ€¢ DeepSeek\nâ€¢ Ollama (æœ¬åœ°éƒ¨ç½²)\n\né…ç½®åï¼ŒAI å°†æ ¹æ®æ‚¨çš„å†…å®¹æ™ºèƒ½ç»­å†™ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿå®Œæˆæ–‡æ¡£åˆ›ä½œã€‚',
    polish: 'è¿™æ˜¯ AI æ¶¦è‰²åŠŸèƒ½çš„æ¼”ç¤ºæ•ˆæœã€‚\n\nğŸ’¡ æç¤ºï¼šè¦ä½¿ç”¨çœŸå®çš„ AI æ¶¦è‰²åŠŸèƒ½ï¼Œè¯·åœ¨å·¥å…·æ çš„ AI è®¾ç½®ä¸­é…ç½®æ‚¨çš„ API Keyã€‚\n\né…ç½®åï¼ŒAI å°†å¸®åŠ©æ‚¨ï¼š\nâ€¢ ä¼˜åŒ–æ–‡å­—è¡¨è¾¾ï¼Œä½¿è¯­å¥æ›´æµç•…\nâ€¢ ä¿®æ­£è¯­æ³•é”™è¯¯\nâ€¢ æå‡ä¸“ä¸šåº¦å’Œå¯è¯»æ€§\nâ€¢ ä¿æŒåŸæ„çš„åŒæ—¶æ”¹å–„æ–‡é£',
    summarize: 'è¿™æ˜¯ AI æ€»ç»“åŠŸèƒ½çš„æ¼”ç¤ºæ•ˆæœã€‚\n\nğŸ’¡ æç¤ºï¼šè¦ä½¿ç”¨çœŸå®çš„ AI æ€»ç»“åŠŸèƒ½ï¼Œè¯·åœ¨å·¥å…·æ çš„ AI è®¾ç½®ä¸­é…ç½®æ‚¨çš„ API Keyã€‚\n\né…ç½®åï¼ŒAI å°†æ™ºèƒ½æå–å†…å®¹è¦ç‚¹ï¼Œç”Ÿæˆç®€æ´çš„æ‘˜è¦ï¼Œå¸®åŠ©è¯»è€…å¿«é€Ÿç†è§£æ ¸å¿ƒä¿¡æ¯ã€‚',
    translate: 'è¿™æ˜¯ AI ç¿»è¯‘åŠŸèƒ½çš„æ¼”ç¤ºæ•ˆæœã€‚\n\nğŸ’¡ Tip: To use the real AI translation feature, please configure your API Key in the AI Settings on the toolbar.\n\nAfter configuration, AI will provide high-quality translations while maintaining the original meaning and style.',
    custom: 'è¿™æ˜¯è‡ªå®šä¹‰ AI å‘½ä»¤çš„æ¼”ç¤ºæ•ˆæœã€‚\n\nğŸ’¡ æç¤ºï¼šè¦ä½¿ç”¨çœŸå®çš„è‡ªå®šä¹‰ AI åŠŸèƒ½ï¼Œè¯·åœ¨å·¥å…·æ çš„ AI è®¾ç½®ä¸­é…ç½®æ‚¨çš„ API Keyã€‚\n\né…ç½®åï¼Œæ‚¨å¯ä»¥è¾“å…¥ä»»ä½•è‡ªå®šä¹‰æŒ‡ä»¤ï¼ŒAI å°†æ ¹æ®æ‚¨çš„è¦æ±‚å¤„ç†é€‰ä¸­çš„æ–‡æœ¬ã€‚',
  }

  const message = demoMessages[demoType]

  try {
    callback.onStart?.()

    // Simulate streaming by sending message character by character
    let index = 0
    const streamInterval = setInterval(() => {
      if (index < message.length) {
        // Send 2-5 characters at a time for more natural streaming
        const chunkSize = Math.floor(Math.random() * 4) + 2
        const chunk = message.slice(index, index + chunkSize)
        callback.onMessage?.({ content: chunk })
        index += chunkSize
      } else {
        clearInterval(streamInterval)
        callback.onStop?.()
      }
    }, 50) // 50ms interval for smooth streaming effect
  } catch (error) {
    callback.onError?.(error instanceof Error ? error : new Error(String(error)))
  }
}

/**
 * Send streaming request to AI provider with timeout control
 */
async function sendStreamingRequest(
  prompt: string,
  content: string,
  callback: AiStreamCallback,
  demoType?: 'continue' | 'polish' | 'summarize' | 'translate' | 'custom'
): Promise<void> {
  const config = getAiConfig()

  // If no API key configured, show demo/simulation instead of error
  if (!config.apiKey) {
    await simulateAiStream(callback, demoType || 'custom')
    return
  }

  const baseUrl = getBaseUrl(config.provider, config.baseUrl)
  const timeout = config.timeout || DEFAULT_TIMEOUT

  // Create AbortController for timeout control
  const controller = new AbortController()
  const timeoutId = setTimeout(() => {
    controller.abort()
  }, timeout)

  let reader: ReadableStreamDefaultReader<Uint8Array> | null = null

  try {
    callback.onStart?.()

    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.apiKey}`,
      },
      body: JSON.stringify({
        model: config.model,
        messages: [
          { role: 'system', content: prompt },
          { role: 'user', content },
        ],
        stream: true,
      }),
      signal: controller.signal,
    })

    if (!response.ok) {
      throw new Error(`AI API error: ${response.status} ${response.statusText}`)
    }

    reader = response.body?.getReader() ?? null
    if (!reader) {
      throw new Error('No response body')
    }

    const decoder = new TextDecoder()
    let buffer = ''

    while (true) {
      const { done, value } = await reader.read()
      if (done) break

      buffer += decoder.decode(value, { stream: true })
      const lines = buffer.split('\n')
      buffer = lines.pop() || ''

      for (const line of lines) {
        if (!line.trim() || !line.startsWith('data: ')) continue
        const data = line.slice(6)
        if (data === '[DONE]') continue

        try {
          const parsed = JSON.parse(data)
          const messageContent = parsed.choices?.[0]?.delta?.content
          if (messageContent) {
            callback.onMessage?.({ content: messageContent })
          }
        } catch {
          // Skip invalid JSON
        }
      }
    }

    callback.onStop?.()
  } catch (error) {
    // Handle abort error specifically
    if (error instanceof Error && error.name === 'AbortError') {
      callback.onError?.(new Error('AI request timeout. Please try again.'))
    } else {
      callback.onError?.(error instanceof Error ? error : new Error(String(error)))
    }
  } finally {
    // Cleanup
    clearTimeout(timeoutId)
    if (reader) {
      try {
        await reader.cancel()
      } catch {
        // Ignore cancel errors
      }
    }
  }
}

/**
 * AI API Service
 * Compatible with the original Kortex aiApiService interface
 */
export const aiApiService = {
  /**
   * Continue writing - streaming
   */
  continueWriting(
    content: string,
    sysPrompt: string,
    callback: AiStreamCallback
  ): void {
    const prompt = `${sysPrompt}\n\nä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·é€‰ä¸­çš„æ–‡å­—ï¼Œç»­å†™æ¥ä¸‹æ¥çš„å†…å®¹ã€‚ä¿æŒåŸæ–‡çš„é£æ ¼å’Œè¯­æ°”ã€‚åªè¾“å‡ºç»­å†™çš„å†…å®¹ï¼Œä¸è¦é‡å¤ç”¨æˆ·é€‰ä¸­çš„æ–‡å­—ã€‚`
    sendStreamingRequest(prompt, content, callback, 'continue')
  },

  /**
   * Polish text - streaming
   */
  polish(
    content: string,
    sysPrompt: string,
    callback: AiStreamCallback
  ): void {
    const prompt = `${sysPrompt}\n\nä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡å­—æ¶¦è‰²åŠ©æ‰‹ã€‚è¯·æ¶¦è‰²ä»¥ä¸‹æ–‡å­—ï¼Œä½¿å…¶æ›´åŠ æµç•…ã€ä¸“ä¸šã€‚ä¿æŒåŸæ„ï¼Œåªè¾“å‡ºæ¶¦è‰²åçš„æ–‡å­—ã€‚`
    sendStreamingRequest(prompt, content, callback, 'polish')
  },

  /**
   * Summarize content - streaming
   */
  summarize(
    content: string,
    sysPrompt: string,
    callback: AiStreamCallback
  ): void {
    const prompt = `${sysPrompt}\n\nä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ€»ç»“åŠ©æ‰‹ã€‚è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹çš„è¦ç‚¹ã€‚ç®€æ´æ˜äº†ï¼Œè¾“å‡ºæ€»ç»“å†…å®¹ã€‚`
    sendStreamingRequest(prompt, content, callback, 'summarize')
  },

  /**
   * Translate text - streaming
   */
  translate(
    content: string,
    targetLang: string,
    sysPrompt: string,
    callback: AiStreamCallback
  ): void {
    const prompt = `${sysPrompt}\n\nä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹å†…å®¹ç¿»è¯‘ä¸º${targetLang}ã€‚åªè¾“å‡ºç¿»è¯‘ç»“æœã€‚`
    sendStreamingRequest(prompt, content, callback, 'translate')
  },

  /**
   * Custom AI command - streaming
   */
  customCommand(
    content: string,
    customPrompt: string,
    sysPrompt: string,
    callback: AiStreamCallback
  ): void {
    const prompt = `${sysPrompt}\n\n${customPrompt}`
    sendStreamingRequest(prompt, content, callback, 'custom')
  },
}
